{% set name = "datasets" %}
{% set version = "3.3.2" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
  sha256: 20901a97da870fb80b407ccc45f034a7ac99accd07da897ed42f11641bdb8c6e

build:
  skip: true  # [py<38]
  entry_points:
    - datasets-cli=datasets.commands.datasets_cli:main
  number: 0
  script: {{ PYTHON }} -m pip install . --no-deps --no-build-isolation --ignore-installed -vv

requirements:
  host:
    - python
    - pip
    - setuptools
    - wheel
  run:
    - python
    - filelock
    - numpy >=1.17
    - pyarrow >=15.0.0
    - dill >=0.3.0,<0.3.9
    - pandas
    - requests >=2.32.2
    - tqdm >=4.66.3
    - python-xxhash
    - multiprocess <0.70.17
    - fsspec >=2023.1.0,<=2024.12.0
    - aiohttp
    - huggingface_hub >=0.24.0
    - packaging
    - pyyaml >=5.1
  run_constrained:
    - apache-beam >=2.26.0
    - tensorflow-base >=2.6.0
    - jax >=0.3.14
    - jaxlib >=0.3.14
    - soundfile >=0.12.1
    - pillow >=9.4.0
    - soxr >=5.1  # [py>=39]

test:
  imports:
    - datasets
    - datasets.commands
    - datasets.utils
  commands:
    - pip check
    - datasets-cli --help
  requires:
    - pip

about:
  home: https://github.com/huggingface/datasets
  summary: HuggingFace community-driven open-source library of datasets
  description: |
    Datasets is a lightweight library providing two main features:

    - one-line dataloaders for many public datasets: one-liners to download and pre-process any of the number of datasets major public datasets (text datasets in 467 languages and dialects, image datasets, audio datasets, etc.) provided on the HuggingFace Datasets Hub. With a simple command like squad_dataset = load_dataset("squad"), get any of these datasets ready to use in a dataloader for training/evaluating a ML model (Numpy/Pandas/PyTorch/TensorFlow/JAX),
    - efficient data pre-processing: simple, fast and reproducible data pre-processing for the above public datasets as well as your own local datasets in CSV/JSON/text/PNG/JPEG/etc. With simple commands like `processed_dataset = dataset.map(process_example)`, efficiently prepare the dataset for inspection and ML model evaluation and training.
  license: Apache-2.0
  license_family: Apache
  license_file: LICENSE  
  doc_url: https://huggingface.co/docs/datasets/index
  dev_url: https://github.com/huggingface/datasets

extra:
  recipe-maintainers:
    - oblute
    - Tata17
    - thewchan
    - mxr-conda
    - wietsedv
